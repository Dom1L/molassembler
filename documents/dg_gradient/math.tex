\documentclass[a4paper]{article}
\usepackage[a4paper,margin=2cm]{geometry}
\usepackage{mathtools}
\usepackage{breqn}
\usepackage[utf8]{inputenc}

\usepackage{tikz} % only for circled numbers
\newcommand*\circled[1]{
  \tikz[baseline=(char.base)]{
    \node[shape=circle,draw,inner sep=2pt] (char) {#1};
  }
}

\renewcommand{\baselinestretch}{1.5}
\setlength{\parindent}{0pt}


\begin{document}
\small

\newcommand{\posVecDiff}[2]{
  \left( \vec{r}_{#1} - \vec{r}_{#2} \right)
}

\newcommand{\vecDiff}[2]{
  \left( \vec{#1} - \vec{#2}\,\right)
}

\newcommand{\vecCross}[2]{
  \left( \vec{#1} \times \vec{#2}\,\right)
}

\newcommand{\posDependence}{
  \left( \left\{\vec{r}_i \right\} \right)
}

\newcommand{\distanceErrorFirstTermPart}{
  \frac{
    \posVecDiff{j}{i}^{2}
  }{
    U_{ij}^{2}
  } - 1
}

\newcommand{\distanceErrorFirstTerm}[1]{
  \textrm{max}^{#1} \left( 
    0, 
    \distanceErrorFirstTermPart
  \right)
}

\newcommand{\distanceErrorSecondTermPart}{
  \frac{
    2 L_{ij}^{2}
  }{
    L_{ij}^{2} + \posVecDiff{j}{i}^{2}
  } - 1
}

\newcommand{\distanceErrorSecondTerm}[1]{
  \textrm{max}^{#1} \left( 
    0,
    \distanceErrorSecondTermPart
  \right)
}

\newcommand{\chiralErrorFirstTerm}[1]{
  \textrm{max}^{#1} \left(
    0,
    V_{ijkl}\posDependence{} - U_{ijkl}
  \right)
}

\newcommand{\chiralErrorSecondTerm}[1]{
  \textrm{max}^{#1} \left(
    0,
    L_{ijkl} - V_{ijkl}\posDependence{} 
  \right)
}

\newcommand{\iNSum}{\sum_{i = 1}^{N}}
\newcommand{\ijNSum}{\sum_{i < j}^{N}}
\newcommand{\chiralSum}{
  \sum_{\left(i, j, k, l, U_{ijkl}, L_{ijkl}\right) \in C} 
}

\newcommand{\volumeCalculationSub}[4]{
  \posVecDiff{#1}{#4}^{T}
  \cdot \left[
    \posVecDiff{#2}{#4}
    \times \posVecDiff{#3}{#4}
  \right]
}

% TODO refactor to vecDiff
\newcommand{\volumeCalculation}[4]{
  \left( \vec{#1} - \vec{#4} \right)^{T}
  \cdot \left[
    \left( \vec{#2} - \vec{#4} \right)
    \times \left( \vec{#3} - \vec{#4} \right)
  \right]
}

\newcommand{\partialPosVec}[1]{
  \frac{\partial}{\partial \vec{r}_{#1}}
}

\newcommand{\partialVec}[1]{
  \frac{\partial}{\partial \vec{#1}\,}
}

\newcommand{\errf}{\textrm{errf}\posDependence}

\section{DG Error function}

For a given set of $N$ particles with positions $\vec{r}_i$, the distance
geometry error function is given as:

\begin{align}\begin{aligned} % nested to get only a single numbered equation
  \errf &= \underbrace {
    \ijNSum \left[
      \distanceErrorFirstTerm{2} + \distanceErrorSecondTerm{2}
    \right]
  }_{\textrm{Distance errors}}\\
  &+ \underbrace{
    \chiralSum \left[ 
      \chiralErrorFirstTerm{2} + \chiralErrorSecondTerm{2}
    \right]^{2}
  }_{\textrm{Chiral errors}},
\end{aligned}\end{align}

where $V_{ijkl}$ is the signed tetrahedron volume spanned by the position vectors of
the indices $\{i, j, k, l\}$

\begin{equation}
  V_{ijkl}\left( \left\{\vec{r}_i \right\} \right) =
    \volumeCalculationSub{i}{j}{k}{l},
\end{equation} \\

$U_{ij}$ and $L_{ij}$ are the upper and lower distance bounds for the atoms
$i$ and $j$, and $U_{ijkl}$ and $L_{ijkl}$ are upper and lower bounds on the
volume spanned by these indices.\\

It is important to note that tetrahedron volumes, e.g.\ $U_{ijkl}$, are
signed values. On odd permutations of indices, these quantities change sign.

\section{Gradient of the error function}

$E$ is scalar-valued, so the columnar gradient of the error function is
composed of partial derivatives to the individual position vectors $\vec{r}_i$:

\begin{align*}
  \nabla E &= \left(
    \frac{\partial E}{\partial \vec{r}_1},
    \frac{\partial E}{\partial \vec{r}_2},
    \ldots,
    \frac{\partial E}{\partial \vec{r}_N}
  \right)
\end{align*}

Each individual component $\left( \partial E / \partial \vec{r}_\alpha \right)$
is a vector whose components are the scalar derivatives:

\begin{align*}
  \frac{\partial E}{\partial \vec{r}_\alpha} &= \begin{pmatrix}
    \partial E / \partial r_{\alpha , x} \\
    \partial E / \partial r_{\alpha , y} \\
    \partial E / \partial r_{\alpha , z} 
  \end{pmatrix}
\end{align*}

We split the problem into the main terms:

\begin{align*}
  \partialPosVec{\alpha} \errf 
  &= \underbrace{
    \partialPosVec{\alpha} \left(
      \ijNSum \distanceErrorFirstTerm{2}
    \right)
  }_{\circled{1}}
  + \underbrace{
    \partialPosVec{\alpha} \left(
      \ijNSum \distanceErrorSecondTerm{2}
    \right)
  }_{\circled{2}}\\
  &+ \underbrace{
    \partialPosVec{\alpha} \chiralSum \chiralErrorFirstTerm{2}
  }_{\circled{3}}\\
  &+ \underbrace{
    \partialPosVec{\alpha} \chiralSum \chiralErrorSecondTerm{2}
  }_{\circled{4}}
\end{align*}

\newpage
And start with \circled{1}. We use the chain rule:

\begin{equation}
  \partialPosVec{\alpha} \ijNSum \distanceErrorFirstTerm{2}
  = 2 \ijNSum \distanceErrorFirstTerm{} \partialPosVec{\alpha}
  \distanceErrorFirstTerm{}.
\end{equation}

If $\alpha = i$, then:

\begin{equation}
  \partialPosVec{i} \distanceErrorFirstTermPart
  = - \frac{2}{U_{ij}^{2}} \posVecDiff{j}{i},
\end{equation}

and likewise, but positive, for $\alpha = j$. Consequently:

\begin{equation}
  \partialPosVec{\alpha} \left( \distanceErrorFirstTerm{} \right)
  = \frac{2}{U_{ij}^{2}} \posVecDiff{j}{i} \left\{ \begin{array}{lr}
    -1 & \textrm{if }\alpha = i\\
    1 & \textrm{if }\alpha = j\\
    0 & \textrm{otherwise}
  \end{array} \right\}
  = \frac{2}{U_{ij}^{2}} \posVecDiff{j}{i} \left(
    \delta_{\alpha j} - \delta_{\alpha i} 
  \right),
\end{equation}

where we have discarded the possibility of $\distanceErrorFirstTermPart < 0$
since this case is adequately covered by the first maximum function. $\delta$ is
the Kronecker delta. So, in total:

\begin{equation}\label{eq_breakdown_deltas}
  \text{\circled{1}}
  = \ijNSum \left(
    \delta_{\alpha j} - \delta_{\alpha i} 
  \right) \underbrace{
    \frac{4}{U_{ij}^{2}} \posVecDiff{j}{i} \distanceErrorFirstTerm{}
  }_{f(i, j)}
\end{equation}

We can transform the summation further using the Kronecker deltas:
\begin{align}
  \ijNSum \left( \delta_{\alpha j} - \delta_{\alpha i} \right) f(i, j)
  &= \sum_{i = 1}^{\alpha - 1} f(i, \alpha) 
    - \sum_{j = \alpha + 1}^{N} f(\alpha, j)\\
  &= \sum_{i = 1}^{\alpha - 1} f(i, \alpha) 
    + \sum_{i = \alpha + 1}^{N} f(i, \alpha)\\
  &= \sum_{i = 1}^{N} \left(1 - \delta_{i\alpha} \right) f(i, \alpha),
\end{align}

where we have used that $f(i, j) = -f(j, i)$ (see Eq.~\ref{eq_breakdown_deltas}).
All in all:

\begin{equation}
  \text{\circled{1}}
  = \iNSum \left(1 - \delta_{i\alpha}\right) \frac{4}{U_{i\alpha}^{2}}
    \posVecDiff{\alpha}{i} \textrm{max} \left(
      0,
      \frac{
        \posVecDiff{\alpha}{i}^{2}
      }{
        U_{i\alpha}^{2}
      } - 1
    \right)
\end{equation}

\newpage
Let us continue with \circled{2}. The chain rule gives:
\begin{equation}
  \partialPosVec{\alpha} \ijNSum \distanceErrorSecondTerm{2}
  = 2 \ijNSum \distanceErrorSecondTerm{} \partialPosVec{\alpha}
    \distanceErrorSecondTerm.
\end{equation}

For $\alpha = i$,
\begin{equation}
  \partialPosVec{i} \left( \distanceErrorSecondTermPart \right)
  = \frac{
    4 L_{ij}^{2} \posVecDiff{j}{i}
  }{
    \left(
      L_{ij}^{2} + \posVecDiff{j}{i}^2
    \right)^2
  },
\end{equation}

and likewise, but negative, for $\alpha = j$. Therefore,

\begin{align*}
  \partialPosVec{\alpha} \left( \distanceErrorSecondTerm{} \right)
  &=\frac{
    4 L_{ij}^{2} \posVecDiff{j}{i}
  }{
    \left(
      L_{ij}^{2} + \posVecDiff{j}{i}^2
    \right)^2
  } \left\{ \begin{array}{lr}
    1 & \textrm{if }\alpha = i\\
    - 1 & \textrm{if }\alpha = j\\
    0 & \textrm{otherwise}
  \end{array} \right\}\\
  &= \frac{
    4 L_{ij}^{2} \posVecDiff{j}{i}
  }{
    \left(
      L_{ij}^{2} + \posVecDiff{j}{i}^2
    \right)^2
  } \left(
    \delta_{\alpha i} - \delta_{\alpha j} 
  \right),
\end{align*}

where we have excluded the possibility of $\distanceErrorSecondTermPart < 0$
since this case is covered by the first maximum function. Altogether:

\begin{equation}\label{eq_breakdown_deltas_second}
  \text{\circled{2}}
  = \ijNSum \left(
    \delta_{\alpha i} - \delta_{\alpha j} 
  \right) \underbrace{
    \frac{
      8 L_{ij}^{2} \posVecDiff{j}{i}
    }{
      \left(
        L_{ij}^{2} + \posVecDiff{j}{i}^2
      \right)^2
    } \distanceErrorSecondTerm{}
  }_{g(i, j)}.
\end{equation}

Transforming the summation:
\begin{align}
  \ijNSum \left( \delta_{\alpha i} - \delta_{\alpha j} \right) g(i, j)
  &= - \sum_{i = 1}^{\alpha - 1} g(i, \alpha) 
    + \sum_{j = \alpha + 1}^{N} g(\alpha, j)\\
  &= \sum_{i = 1}^{\alpha - 1} g(\alpha, i) 
    + \sum_{i = \alpha + 1}^{N} g(\alpha, i)\\
  &= \sum_{i = 1}^{N} \left(1 - \delta_{i\alpha} \right) g(\alpha, i),
\end{align}

Where we have used $g(i, j) = -g(j, i)$ (see
Eq.~\ref{eq_breakdown_deltas_second}). All in all:

\begin{equation}
  \text{\circled{2}}
  = \iNSum \left(1 - \delta_{i\alpha}\right) 
    \frac{
      8 L_{\alpha i}^{2} \posVecDiff{i}{\alpha}
    }{
      \left(
        L_{\alpha i}^{2} + \posVecDiff{i}{\alpha}^2
      \right)^2
    } \textrm{max} \left(
      0,
      \frac{
        2 L_{\alpha i}^{2}
      }{
        L_{\alpha i}^{2} + \posVecDiff{i}{\alpha}^{2}
      } - 1
    \right)
\end{equation}

\newpage
Next, we consider \circled{3}. Applying the chain rule gives:

\begin{align*}
  &\quad\partialPosVec{\alpha} \chiralSum \chiralErrorFirstTerm{2}\\
  &= 2 \chiralSum \chiralErrorFirstTerm{} \partialPosVec{\alpha} \chiralErrorFirstTerm{}
\end{align*}

The partial derivatives of $V_{ijkl}\posDependence$ for $\alpha \in \{i, j, k,
l\}$ are as follows:

\begin{align}
  \text{\circled{i}} &\quad \partialVec{i} \left\{ 
    \vecDiff{i}{l}^{T}
    \cdot \left[
      \vecDiff{j}{l}
      \times \vecDiff{k}{l}
    \right]
  \right\} \\
  &= \partialVec{i} \left\{ 
    \vec{i}^{\,T}
    \cdot \left[
      \vecDiff{j}{l}
      \times \vecDiff{k}{l}
    \right]
  \right\} - \vec{0} \\
  &= \vecDiff{j}{l} \times \vecDiff{k}{l} 
\end{align}

\begin{align}
  \text{\circled{j}} &\quad \partialVec{j} 
    \vecDiff{i}{l}^{T}
    \cdot \left[
      \vecDiff{j}{l}
      \times \vecDiff{k}{l}
    \right] \\
  &= \partialVec{j}
    \vecDiff{i}{l}^{T}
    \cdot \left[
      \vec{j} \times \vec{k} - \vec{j} \times \vec{l} - \vec{l} \times \vec{k} + \underbrace{
        \vec{l} \times \vec{l}
      }_{=0}
    \right] \\
  &= \partialVec{j} \left\{
    \vec{j}^{\,T} \cdot \left[
      \vec{k} \times \vecDiff{i}{l}
    \right] 
    - \vec{j}^{\,T} \cdot \left[
      \vec{l} \times \vecDiff{i}{l}
    \right] 
  \right\} - \vec{0} \\
  &= \vecDiff{k}{l} \times \vecDiff{i}{l} 
  = - \vecDiff{i}{l} \times \vecDiff{k}{l}
\end{align}

\begin{align}
  \text{\circled{k}} &\quad \partialVec{k} 
    \vecDiff{i}{l}^{T}
    \cdot \left[
      \vec{j} \times \vec{k} - \vec{j} \times \vec{l} - \vec{l} \times \vec{k} 
    \right] \\
  &= \partialVec{k} \left\{
    \vec{k}^{\,T} \cdot \left[
      \vecDiff{i}{l} \times \vec{j}
    \right] 
    - \vec{k}^{\,T} \cdot \left[
      \vecDiff{i}{l} \times \vec{l}\,
    \right] 
  \right\} - \vec{0} \\
  &= \vecDiff{i}{l} \times \vecDiff{j}{l} 
\end{align}

\begin{align}
  \text{\circled{l}} &\quad \frac{\partial}{\partial \vec{l}\,} 
    \vecDiff{i}{l}^{T}
    \cdot \left[
      \vec{j} \times \vec{k} - \vec{j} \times \vec{l} - \vec{l} \times \vec{k} 
    \right] \\
  &= \frac{\partial}{\partial \vec{l}\,}\, \vec{i}^{\,T} \cdot \left[
      \vec{j} \times \vec{k} - \vec{j} \times \vec{l} - \vec{l} \times \vec{k} 
    \right] - \frac{\partial}{\partial \vec{l}\,} \vec{l}^{\,\,T} \cdot \left[
      \vec{j} \times \vec{k} - \vec{j} \times \vec{l} - \vec{l} \times \vec{k}
    \right]\\
  &= \underbrace{
      \frac{\partial}{\partial \vec{l}\,} \vec{i}^{\,T} \cdot \vecCross{j}{k}
    }_{=0} 
    - \frac{\partial}{\partial \vec{l}\,} \vec{i}^{\,T} \cdot \left( 
      \vec{j} \times \vec{l}\,
    \right)
    - \frac{\partial}{\partial \vec{l}\,} \vec{i}^{\,T} \cdot \vecCross{l}{k}
    - \frac{\partial}{\partial \vec{l}\,} \vec{l}^{\,\,T} \cdot \vecCross{j}{k}
    + \frac{\partial}{\partial \vec{l}\,} \underbrace{
      \vec{l}^{\,\,T} \cdot \vecCross{l}{k} 
    }_{=0}
    + \frac{\partial}{\partial \vec{l}\,} \underbrace{
      \vec{l}^{\,\,T} \cdot \vecCross{j}{l}
    }_{=0} \\
  &= - \frac{\partial}{\partial \vec{l}\,} \vec{l}^{\,\,T} \cdot \vecCross{k}{i}
    - \frac{\partial}{\partial \vec{l}\,} \vec{l}^{\,\,T} \cdot \vecCross{i}{j}
    - \frac{\partial}{\partial \vec{l}\,} \vec{l}^{\,\,T} \cdot \vecCross{j}{k} \\
  &= - \vec{k} \times \vec{i} - \vec{i} \times \vec{j} - \vec{j} \times \vec{k} \\
  &= - \vecDiff{i}{k} \times \vecDiff{j}{k} 
\end{align}

So, overall:

\begin{equation}
  \text{\circled{3}} = \chiralSum 2\ \chiralErrorFirstTerm{} \left\{ \begin{array}{rr}
    \posVecDiff{j}{l} \times \posVecDiff{k}{l} & \textrm{if }\alpha = i\\
    - \posVecDiff{i}{l} \times \posVecDiff{k}{l} & \textrm{if }\alpha = j\\
    \posVecDiff{i}{l} \times \posVecDiff{j}{l} & \textrm{if }\alpha = k\\
    - \posVecDiff{i}{k} \times \posVecDiff{j}{k} & \textrm{if }\alpha = l\\
    0 & \textrm{otherwise}
  \end{array} \right\}.
\end{equation}

For \circled{4}, the derivation is analog save for the sign of the great amount
of cases, which we extrude from the sum:

\begin{equation}
  \text{\circled{4}} = - \chiralSum 2\ \chiralErrorSecondTerm{} \left\{ \begin{array}{rr}
    \posVecDiff{j}{l} \times \posVecDiff{k}{l} & \textrm{if }\alpha = i\\
    - \posVecDiff{i}{l} \times \posVecDiff{k}{l} & \textrm{if }\alpha = j\\
    \posVecDiff{i}{l} \times \posVecDiff{j}{l} & \textrm{if }\alpha = k\\
    - \posVecDiff{i}{k} \times \posVecDiff{j}{k} & \textrm{if }\alpha = l\\
    0 & \textrm{otherwise}
  \end{array} \right\}.
\end{equation}

Both terms concerning the chiral error can be summarized as follows:

\begin{align*}
  &\quad\chiralSum 2\ \chiralErrorFirstTerm{} \Big\{ \ldots \Big\}
  - \chiralSum 2\ \chiralErrorSecondTerm{} \Big\{ \ldots \Big\}\\
  &= \chiralSum 2\ \Big\{ \ldots \Big\} \Big[ 
    \chiralErrorFirstTerm{} - \chiralErrorSecondTerm{} 
  \Big],
\end{align*}

which ought to save some time in an implementation.

\end{document}
